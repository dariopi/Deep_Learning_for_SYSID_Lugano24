{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from pytorch-ident, https://github.com/forgi86/pytorch-ident/blob/master/torchid/ss/dt/simulator.py\n",
    "\n",
    "class StateSpaceSimulator(nn.Module):\n",
    "    r\"\"\" Discrete-time state-space simulator.\n",
    "\n",
    "    Args:\n",
    "        f_xu (nn.Module): The neural state-space model.\n",
    "        batch_first (bool): If True, first dimension is batch.\n",
    "\n",
    "    Inputs: x_0, u\n",
    "        * **x_0**: tensor of shape :math:`(N, n_{x})` containing the\n",
    "          initial hidden state for each element in the batch.\n",
    "          Defaults to zeros if (h_0, c_0) is not provided.\n",
    "        * **input**: tensor of shape :math:`(L, N, n_{u})` when ``batch_first=False`` or\n",
    "          :math:`(N, L, n_{x})` when ``batch_first=True`` containing the input sequence\n",
    "\n",
    "    Outputs: x\n",
    "        * **x**: tensor of shape :math:`(L, N, n_{x})` corresponding to\n",
    "          the simulated state sequence.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> ss_model = NeuralStateSpaceModel(n_x=3, n_u=2)\n",
    "        >>> nn_solution = StateSpaceSimulator(ss_model)\n",
    "        >>> x0 = torch.randn(64, 3)\n",
    "        >>> u = torch.randn(100, 64, 2)\n",
    "        >>> x = nn_solution(x0, u)\n",
    "        >>> print(x.size())\n",
    "        torch.Size([100, 64, 3])\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, f_xu, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.f_xu = f_xu\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x_0, u):\n",
    "        x_step = x_0\n",
    "        dim_time = 1 if self.batch_first else 0\n",
    "        x = []\n",
    "        for u_step in u.split(1, dim=dim_time):  # split along the time axis\n",
    "            u_step = u_step.squeeze(dim_time)\n",
    "            x += [x_step]\n",
    "            dx = self.f_xu(x_step, u_step)\n",
    "            x_step = x_step + dx\n",
    "\n",
    "        x = torch.stack(x, dim_time)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StateSpaceSimulatorBasic(nn.Module):\n",
    "    def __init__(self, f_xu, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.f_xu = f_xu\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x_0, u):\n",
    "        B, n_x = x_0.shape\n",
    "        _, T, _ = u.shape # B, T, n_u\n",
    "        x = torch.empty((B, T, n_x))\n",
    "        x_step = x_0\n",
    "        for t in range(T):  # split along the time axis\n",
    "            x[:, [t], :] = x_step\n",
    "            dx = self.f_xu(x_step, u[:, t, :])\n",
    "            x_step = x_step + dx\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from pytorch-ident, https://github.com/forgi86/pytorch-ident/blob/master/torchid/ss/dt/models.py\n",
    "class NeuralStateUpdate(nn.Module):\n",
    "\n",
    "    def __init__(self, n_x=2, n_u=1, n_feat=32):\n",
    "        super(NeuralStateUpdate, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_x+n_u, n_feat),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_feat, n_x),\n",
    "        )\n",
    "        \n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=1e-2)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "\n",
    "    def forward(self, x, u):\n",
    "        z = torch.cat((x, u), dim=-1)\n",
    "        dx = self.net(z)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y = 1; n_x = 2; n_u = 1;\n",
    "B = 1; # just one sequence\n",
    "u = torch.randn((B, 1024, n_u)) # replace with actual training input\n",
    "y = torch.randn((B, 1024, n_y)) # replace with actual training output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.zeros((B, n_x), requires_grad=True) # this is also a training variable\n",
    "f_xu = NeuralStateUpdate(n_x, n_u, n_feat=32)\n",
    "simulator = StateSpaceSimulator(f_xu) # \n",
    "#g_x = NeuralOutput(n_x, n_y, n_feat=32) # an MLP with n_x input and n_y outputs, to be defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW([\n",
    "        {'params': f_xu.parameters(),    'lr': 1e-3},\n",
    "        #{'params': g_x.parameters(),    'lr': 1e-3},\n",
    "        {'params':x0 , 'lr': 1e-3},\n",
    "    ], 1e-3\n",
    ")\n",
    "#opt = torch.optim.AdamW(list(f_xu.parameters()) + list(g_x.parameters()) + [x0], 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sim = simulator(x0, u) # B, T, n_x\n",
    "#y_sim = g_x(x_sim) # # B, T, n_y\n",
    "#loss = torch.nn.functional.mse_loss(y, y_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
