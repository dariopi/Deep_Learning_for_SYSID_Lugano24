{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from pytorch-ident, https://github.com/forgi86/pytorch-ident/blob/master/torchid/ss/dt/simulator.py\n",
    "\n",
    "class StateSpaceSimulator(nn.Module):\n",
    "    r\"\"\" Discrete-time state-space simulator.\n",
    "\n",
    "    Args:\n",
    "        f_xu (nn.Module): The neural state-space model.\n",
    "        batch_first (bool): If True, first dimension is batch.\n",
    "\n",
    "    Inputs: x_0, u\n",
    "        * **x_0**: tensor of shape :math:`(N, n_{x})` containing the\n",
    "          initial hidden state for each element in the batch.\n",
    "          Defaults to zeros if (h_0, c_0) is not provided.\n",
    "        * **input**: tensor of shape :math:`(L, N, n_{u})` when ``batch_first=False`` or\n",
    "          :math:`(N, L, n_{x})` when ``batch_first=True`` containing the input sequence\n",
    "\n",
    "    Outputs: x\n",
    "        * **x**: tensor of shape :math:`(L, N, n_{x})` corresponding to\n",
    "          the simulated state sequence.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> ss_model = NeuralStateSpaceModel(n_x=3, n_u=2)\n",
    "        >>> nn_solution = StateSpaceSimulator(ss_model)\n",
    "        >>> x0 = torch.randn(64, 3)\n",
    "        >>> u = torch.randn(100, 64, 2)\n",
    "        >>> x = nn_solution(x0, u)\n",
    "        >>> print(x.size())\n",
    "        torch.Size([100, 64, 3])\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, f_xu, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.f_xu = f_xu\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x_0, u):\n",
    "        x_step = x_0\n",
    "        dim_time = 1 if self.batch_first else 0\n",
    "        x = []\n",
    "        for u_step in u.split(1, dim=dim_time):  # split along the time axis\n",
    "            u_step = u_step.squeeze(dim_time)\n",
    "            x += [x_step]\n",
    "            dx = self.f_xu(x_step, u_step)\n",
    "            x_step = x_step + dx\n",
    "\n",
    "        x = torch.stack(x, dim_time)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateSpaceSimulatorBasic(nn.Module):\n",
    "    def __init__(self, f_xu, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.f_xu = f_xu\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x_0, u):\n",
    "        B, n_x = x_0.shape\n",
    "        _, T, _ = u.shape # B, T, n_u\n",
    "        x = torch.empty((B, T, n_x))\n",
    "        x_step = x_0\n",
    "        for t in range(T):  # split along the time axis\n",
    "            x[:, [t], :] = x_step\n",
    "            dx = self.f_xu(x_step, u[:, t, :])\n",
    "            x_step = x_step + dx\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from pytorch-ident, https://github.com/forgi86/pytorch-ident/blob/master/torchid/ss/dt/models.py\n",
    "class NeuralStateUpdate(nn.Module):\n",
    "\n",
    "    def __init__(self, n_x=2, n_u=1, n_feat=32):\n",
    "        super(NeuralStateUpdate, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_x+n_u, n_feat),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_feat, n_x),\n",
    "        )\n",
    "        \n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=1e-2)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "\n",
    "    def forward(self, x, u):\n",
    "        z = torch.cat((x, u), dim=-1)\n",
    "        dx = self.net(z)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralOutput(nn.Module):\n",
    "\n",
    "    def __init__(self, n_x, n_y, n_feat=32):\n",
    "        super(NeuralOutput, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_x, n_feat),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_feat, n_y),\n",
    "        )\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CascadedTanksNeuralStateSpaceModel(nn.Module):\n",
    "    r\"\"\"A state-space model to represent the cascaded two-tank system.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        n_feat: (int, optional): Number of input features in the hidden layer. Default: 0\n",
    "        scale_dx: (str): Scaling factor for the neural network output. Default: 1.0\n",
    "        init_small: (boolean, optional): If True, initialize to a Gaussian with mean 0 and std 10^-4. Default: True\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_feat=64, init_small=True):\n",
    "        super(CascadedTanksNeuralStateSpaceModel, self).__init__()\n",
    "        self.n_feat = n_feat\n",
    "\n",
    "        # Neural network for the first state equation = NN(x_1, u)\n",
    "        self.net1 = nn.Sequential(\n",
    "            nn.Linear(2, n_feat),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_feat, 1),\n",
    "        )\n",
    "\n",
    "        # Neural network for the first state equation = NN(x_1, x2)\n",
    "        self.net2 = nn.Sequential(\n",
    "            nn.Linear(2, n_feat),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_feat, 1),\n",
    "        )\n",
    "\n",
    "        # Small initialization is better for multi-step methods\n",
    "        if init_small:\n",
    "            for m in self.net1.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.normal_(m.weight, mean=0, std=1e-4)\n",
    "                    nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "        # Small initialization is better for multi-step methods\n",
    "        if init_small:\n",
    "            for m in self.net2.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.normal_(m.weight, mean=0, std=1e-4)\n",
    "                    nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, in_x, in_u):\n",
    "\n",
    "        # the first state derivative is NN(x1, u)\n",
    "        in_1 = torch.cat((in_x[..., [0]], in_u), -1)  # concatenate 1st state component with input\n",
    "        dx_1 = self.net1(in_1)\n",
    "\n",
    "        # the second state derivative is NN(x1, x2)\n",
    "        in_2 = in_x\n",
    "        dx_2 = self.net2(in_2)\n",
    "\n",
    "        # the state derivative is built by concatenation of dx_1 and dx_2, possibly scaled for numerical convenience\n",
    "        dx = torch.cat((dx_1, dx_2), -1)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CascadedTanksOverflowNeuralStateSpaceModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_feat=64, init_small=True):\n",
    "        super(CascadedTanksOverflowNeuralStateSpaceModel, self).__init__()\n",
    "        self.n_feat = n_feat\n",
    "\n",
    "        # Neural network for the first state equation = NN(x_1, u)\n",
    "        self.net1 = nn.Sequential(\n",
    "            nn.Linear(2, n_feat),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(n_feat, n_feat),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(n_feat, 1),\n",
    "        )\n",
    "\n",
    "        # Neural network for the first state equation = NN(x_1, x2, u) # we assume that with overflow the input may influence the 2nd tank instantaneously\n",
    "        self.net2 = nn.Sequential(\n",
    "            nn.Linear(3, n_feat),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(n_feat, n_feat),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(n_feat, 1),\n",
    "        )\n",
    "\n",
    "        # Small initialization is better for multi-step methods\n",
    "        if init_small:\n",
    "            for m in self.net1.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.normal_(m.weight, mean=0, std=1e-4)\n",
    "                    nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "        # Small initialization is better for multi-step methods\n",
    "        if init_small:\n",
    "            for m in self.net2.modules():\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.normal_(m.weight, mean=0, std=1e-4)\n",
    "                    nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "    def forward(self, in_x, in_u):\n",
    "\n",
    "        # the first state derivative is NN_1(x1, u)\n",
    "        in_1 = torch.cat((in_x[..., [0]], in_u), -1)  # concatenate 1st state component with input\n",
    "        dx_1 = self.net1(in_1)\n",
    "\n",
    "        # the second state derivative is NN_2(x1, x2, u)\n",
    "        in_2 = torch.cat((in_x, in_u), -1) # concatenate states with input to define the\n",
    "        dx_2 = self.net2(in_2)\n",
    "\n",
    "        # the state derivative is built by concatenation of dx_1 and dx_2, possibly scaled for numerical convenience\n",
    "        dx = torch.cat((dx_1, dx_2), -1)\n",
    "        dx = dx\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y = 1\n",
    "n_x = 2\n",
    "n_u = 1\n",
    "batch_size, seq_len = 32, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_u = torch.randn((batch_size, seq_len, n_u))\n",
    "batch_y = torch.randn((batch_size, seq_len, n_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_xu = NeuralStateUpdate(n_x, n_u, n_feat=64)\n",
    "model = StateSpaceSimulator(f_xu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x0 = torch.zeros(batch_size, n_x)\n",
    "batch_x_sim = model(batch_x0, batch_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 256, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y = 1; n_x = 2; n_u = 1;\n",
    "f_xu = NeuralStateUpdate(n_x, n_u, n_feat=64)\n",
    "model = StateSpaceSimulator(f_xu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 256, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T = 32, 256 # batch size, sequence length\n",
    "batch_x0 = torch.zeros(batch_size, n_x) # B, n_x\n",
    "batch_u = torch.randn((batch_size, seq_len, n_u)) # B, T, n_u\n",
    "batch_x_sim = model(batch_x0, batch_u) # B, T, n_x\n",
    "batch_x_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y = 1; n_x = 2; n_u = 1;\n",
    "B = 1; # just one sequence\n",
    "u = torch.randn((B, 1024, n_u)) # replace with actual training input\n",
    "y = torch.randn((B, 1024, n_y)) # replace with actual training output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.zeros((B, n_x), requires_grad=True) # this is also a training variable\n",
    "f_xu = NeuralStateUpdate(n_x, n_u, n_feat=32)\n",
    "simulator = StateSpaceSimulator(f_xu) # \n",
    "g_x = NeuralOutput(n_x, n_y, n_feat=32) # an MLP with n_x input and n_y outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW([\n",
    "        {'params': f_xu.parameters(),    'lr': 1e-3},\n",
    "        {'params': g_x.parameters(),    'lr': 1e-3},\n",
    "        {'params':x0 , 'lr': 1e-3},\n",
    "    ], 1e-3\n",
    ")\n",
    "#opt = torch.optim.AdamW(list(f_xu.parameters()) + list(g_x.parameters()) + [x0], 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sim = simulator(x0, u) # B, T, n_x\n",
    "y_sim = g_x(x_sim) # # B, T, n_y\n",
    "loss = torch.nn.functional.mse_loss(y, y_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
