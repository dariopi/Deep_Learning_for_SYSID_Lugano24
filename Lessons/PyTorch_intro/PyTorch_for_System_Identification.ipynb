{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b5c32e-d534-435e-bec8-44a7af94629e",
   "metadata": {},
   "source": [
    "# PyTorch for system identification problems\n",
    "\n",
    "## Course on Deep Learning for System Identification\n",
    "## Authors: Gabriele Maroni\n",
    "## Lugano, April 22th, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63cbb33-5938-4f27-ab85-c0694867e1f9",
   "metadata": {},
   "source": [
    "In this tutorial, we will address a system identification problem using PyTorch, focusing on the development and training of neural networks specifically designed for input-output sequence prediction:\n",
    "\n",
    "1. **Converting System Identification to Supervised Regression**: We'll explain how a system identification problem can be modeled as a supervised regression problem and how to use classical models, such as linear models and Feed-Forward Neural Networks (FFNNs) to solve it.\n",
    "\n",
    "2. **Understanding Prediction Errors**: We will distinguish between one-step-ahead prediction error and simulation error, outlining their implications for model performance and training.\n",
    "\n",
    "3. **Developing Sequence-Specific Neural Architectures**: Special focus will be placed on designing neural networks suitable for sequence problems, such as Recurrent Neural Networks (RNNs) and Long Short-Term Memory networks (LSTMs). We'll delve into the architectural choices that help capture temporal dependencies in data.\n",
    "\n",
    "4. **Utilizing Dataset and DataLoader for Sequences**: To manage sequence data efficiently during training and minimize simulation errors, we will use PyTorchâ€™s `Dataset` and `DataLoader` functionalities. This includes creating Datasets that fetch sequences from the original dataset and configuring DataLoaders to batch and shuffle these sequences optimally.\n",
    "\n",
    "By the end of this tutorial, you will have a comprehensive understanding of how to implement these advanced techniques in PyTorch, crucial for solving system identification problems effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e72d8f-5e31-49e6-81fb-40ffb88f28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import *\n",
    "from configs import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "rcParams.update(fig_params)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224598e-e5ed-4242-837c-425b1c37dec4",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcbad91-b05f-4af1-b890-cb584a60067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed value for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Dataset path\n",
    "dataset_folder = os.path.join('..', '..', 'Datasets', 'MassSpringDamper')\n",
    "dataset_path = os.path.join(dataset_folder, 'mass_spring_damper_nonlinear.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857dad5-ddf5-44ce-8343-f7971e654f95",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feaa9bc-961b-4fb3-b4e7-aecbdaa27b3c",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: flex-start;\">\n",
    "    <div style=\"flex: 1; padding-right: 20px;\">\n",
    "        The dataset that will be used in this notebook is generated simulating a nonlinear mass spring damper system.<br>\n",
    "        The nonlinearity is introduced in the spring component.\n",
    "        $$\n",
    "        f_{spring}(x) = k x + \\alpha x^3 \\quad \\alpha > 0 \\quad \\text{(hardening spring)}\n",
    "        $$\n",
    "        The system can be described by the following equation: \n",
    "        $$\n",
    "        F - c\\dot{x} - k x - \\alpha x^3 = m\\ddot{x}\n",
    "        $$\n",
    "        Rearranging the equation we get:\n",
    "        $$\n",
    "        \\ddot{x} = \\frac{1}{m}(F - c\\dot{x} - k x - \\alpha x^3)\n",
    "        $$\n",
    "        Setting $x_1 = x$, $x_2 = \\dot{x}$ and $y = x_1$ we can write the system in state space form:\n",
    "        \\begin{align}\n",
    "            \\dot{x_1} &= x_2 \\\\\n",
    "            \\dot{x_2} &= \\frac{1}{m}(F - c x_2 - k x_1 - \\alpha x_1^3) \\\\\n",
    "            y &= x_1\n",
    "        \\end{align}\n",
    "    </div>\n",
    "    <div style=\"display: flex; flex-direction: column; align-items: center; justify-content: center;\">\n",
    "        <div>\n",
    "            <img src=\"images/MSD.png\" width=\"250\" height=\"250\" alt=\"Nonlinear mass spring damper system\">\n",
    "            <div style=\"text-align: center;\">Nonlinear mass spring damper system [1]</div>\n",
    "        </div>\n",
    "        <div>\n",
    "            <img src=\"images/spring.png\" width=\"400\" height=\"400\" alt=\"Spring types\">\n",
    "            <div style=\"text-align: center;\">Spring types [2]</div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5f1f2-0675-4a48-94c7-b77160064c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, target = load_sysid_dataset(dataset_path,\n",
    "                                snr_db=35, # signal to noise ratio in dB\n",
    "                                seed=SEED)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e2005c-b38f-42e3-8c9d-125807c6938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,6))\n",
    "gs = fig.add_gridspec(2, hspace=0.1)\n",
    "axs = gs.subplots(sharex=True, sharey=False)\n",
    "fig.suptitle('Data')\n",
    "axs[0].plot(df['t'], df['u(t)'], color='tab:blue')\n",
    "axs[0].set_ylabel('u(t)')\n",
    "axs[0].margins(0.0)\n",
    "\n",
    "axs[1].plot(df['t'], df['y(t)'], color='tab:blue')\n",
    "axs[1].set_ylabel('y(t)')\n",
    "axs[1].set_xlabel('t')\n",
    "axs[1].margins(0.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d281d-b2d4-4cad-b00b-555bcb048b20",
   "metadata": {},
   "source": [
    "## Converting System Identification to Supervised Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbdd13-8b5d-47d5-a8c5-8ef9c4e38980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regressors(df, na, nb, dropna=True):\n",
    "    t, u, y = df['t'].values, df['u(t)'].values, df['y(t)'].values\n",
    "    n = y.shape[0]\n",
    "    phi = pd.DataFrame(data=zip(t, u, y), index=range(n), columns=['t', 'u(t)', 'y(t)'])\n",
    "    regressors = ['u(t)']\n",
    "    \n",
    "    for tau_b in range(1, nb+1):\n",
    "        phi[f'u(t-{tau_b})'] = phi['u(t)'].shift(tau_b)\n",
    "        regressors.append(f'u(t-{tau_b})')\n",
    "    for tau_a in range(1, na+1):\n",
    "        phi[f'y(t-{tau_a})'] = phi['y(t)'].shift(tau_a)\n",
    "        regressors.append(f'y(t-{tau_a})')\n",
    "\n",
    "    if dropna:\n",
    "        phi.dropna(inplace=True)\n",
    "\n",
    "    return phi[['t'] + regressors + ['y(t)']], regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c67d30-5eb7-4d61-aeef-f59c0a47caed",
   "metadata": {},
   "source": [
    "The function `create_regressors` compute and organizing regressors (or features) from input-output sequence data. This function essentially prepares the dataset for regression by creating lagged versions of input ($u$) and output ($y$) variables, facilitating the modeling of temporal relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212ae0d-9ab4-4639-a5bf-1a71275a1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = 2\n",
    "nb = 2\n",
    "\n",
    "df, regressors = create_regressors(df, na=na, nb=nb, dropna=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9378ef-bc7a-4f1c-a292-86e9b4a71e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4479c1-14c7-4089-ace0-0ff2314c317d",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8491c02-fbec-44b9-a394-fb4a0f411952",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c50c893-4cf7-4e55-b068-b4949c5e4683",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,6))\n",
    "gs = fig.add_gridspec(2, hspace=0.1)\n",
    "axs = gs.subplots(sharex=True, sharey=False)\n",
    "fig.suptitle('Data')\n",
    "axs[0].plot(train['t'], train['u(t)'], label='train', color='tab:blue')\n",
    "axs[0].plot(test['t'], test['u(t)'], label='test', color='tab:blue', linestyle='--')\n",
    "axs[0].axvline(train.iloc[-1]['t'], linestyle='--', color='k', linewidth=2.5)\n",
    "axs[0].set_ylabel('u(t)')\n",
    "axs[0].margins(0.0)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(train['t'], train['y(t)'], label='train', color='tab:blue')\n",
    "axs[1].plot(test['t'], test['y(t)'], label='test', color='tab:blue', linestyle='--')\n",
    "axs[1].axvline(train.iloc[-1]['t'], linestyle='--', color='k', linewidth=2.5)\n",
    "axs[1].set_ylabel('y(t)')\n",
    "axs[1].set_xlabel('t')\n",
    "axs[1].margins(0.0)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923f467-8414-4be9-a8c4-f78d1a7e9ffc",
   "metadata": {},
   "source": [
    "## Modeling: linear baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85538154-1b6a-41a1-a01b-0895c0842c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(train[regressors], train[target].values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922869ce-caa9-4786-9b45-03b8c89a2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve learned coefficients\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e39002-45b9-49e9-bbf4-1d63f6d982e1",
   "metadata": {},
   "source": [
    "### Predicting and computing evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1223dc78-cb9d-47fd-94e2-1828a25e7706",
   "metadata": {},
   "source": [
    "#### One-step ahead prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503c53a-62db-4344-bf64-51d32df8cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train prediction\n",
    "y_pred_train = model.predict(train[regressors])\n",
    "# Test prediction\n",
    "y_pred_test = model.predict(test[regressors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60f028-f217-454c-b0a0-ef7e798feb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics on train\n",
    "calculate_metrics(train[target], y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6142644-1166-4225-b97e-3e69035ae86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics on test\n",
    "calculate_metrics(test[target], y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6514bd88-a2b4-429e-af42-795d489cd4ec",
   "metadata": {},
   "source": [
    "#### Simulation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b1c23-9c4d-430f-a622-5a8f7c8a4ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate on test set\n",
    "y_sim_test_linear = simulate(model, test[regressors], na=na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627cbfb-afba-4f2b-84b6-370555e5979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics on test\n",
    "calculate_metrics(test[target], y_sim_test_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc26ce-4f12-4738-8305-c333aa6cdf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,6))\n",
    "gs = fig.add_gridspec(2, hspace=0.1)\n",
    "axs = gs.subplots(sharex=True, sharey=False)\n",
    "\n",
    "axs[0].plot(test['t'], test[target], label='True', color='b')\n",
    "axs[0].plot(test['t'], y_sim_test_linear, label='Simulated', color='r', linestyle='-')\n",
    "axs[0].set_ylabel(r'$y(t)$')\n",
    "axs[0].margins(0.0)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(test['t'], test[target].values.reshape(-1,1) - y_sim_test_linear, label='Simulation error', color='r')\n",
    "axs[1].set_ylabel(r'$y(t) - \\hat{y}_{sim}(t)$')\n",
    "axs[1].set_xlabel('t')\n",
    "axs[1].margins(0.0)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5bc7d1-7f9b-4113-bee7-2499c5c7327f",
   "metadata": {},
   "source": [
    "## Modeling: Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cffafc4-ca71-4cbf-bf8a-40788a6a78fe",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa4c13-e4ff-4031-afa9-d07e555ae56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "x_scaler = StandardScaler()\n",
    "x_train_df = pd.DataFrame(data=x_scaler.fit_transform(train[regressors]), index=train.index, columns=regressors)\n",
    "x_test_df = pd.DataFrame(data=x_scaler.transform(test[regressors]), index=test.index, columns=regressors)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(train[target].values.reshape(-1,1))\n",
    "y_test = y_scaler.transform(test[target].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efbd840-8679-48c8-9df9-7290829f136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to PyTorch tensors\n",
    "x_train = torch.from_numpy(x_train_df.values).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(x_test_df.values).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763365b6-fb29-4d92-bcc7-c284dafc1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        layers = []\n",
    "        # Adding the first hidden layer that connects the input layer to the first hidden layer\n",
    "        layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        # Creating subsequent hidden layers\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        # Adding the output layer\n",
    "        layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        # Wrap all layers in ModuleList so they are properly registered.\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb28a9-dc4f-4c8c-b103-c932268b54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# Datasets\n",
    "train_dataset = RegressionDataset(x_train, y_train)\n",
    "test_dataset = RegressionDataset(x_test, y_test)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcf3067-0555-4e4b-9daa-8a8d4382857b",
   "metadata": {},
   "source": [
    "### Training set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a149f43-6160-4b26-884c-dc96faf34f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "\n",
    "# Instantiate the model\n",
    "model = FeedForwardNN(input_size=x_train.shape[1],\n",
    "                      hidden_sizes=[20,20],\n",
    "                      output_size=y_train.shape[1])\n",
    "print(f\"Total number of trainable model parameters: {get_model_num_params(model)}\")\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define loss function\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Calculate loss value with untrained model to use as reference\n",
    "y_pred_train = model(x_train)\n",
    "loss0 = loss_function(y_pred_train, y_train).item()\n",
    "print(f\"Initial loss: {loss0:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50454ce-0f41-422c-95de-29564925c7dc",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608138d-141f-4a1f-a278-ec6cae138222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = 1000\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    loss = 0.0\n",
    "    for x_train_batch, y_train_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred_train_batch = model(x_train_batch)\n",
    "        loss_batch = loss_function(y_pred_train_batch, y_train_batch)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        loss += loss_batch.item() * x_train_batch.size(0)\n",
    "\n",
    "    # Average loss\n",
    "    loss /= train.shape[0]\n",
    "\n",
    "    # Logging\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch:03d}/{epochs:03d}\"\n",
    "              f\" | Train Loss: {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d997830a-cd41-4218-a0e6-23a57849a408",
   "metadata": {},
   "source": [
    "### Predicting and computing evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6ee69-96cb-41c6-8813-b7514c6606b9",
   "metadata": {},
   "source": [
    "#### One-step ahead prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6f5a6-847a-4373-9375-34c565a7192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Train prediction\n",
    "    y_pred_train = model(x_train)\n",
    "    # Test prediction\n",
    "    y_pred_test = model(x_test)\n",
    "    \n",
    "    # Invert scaling operation\n",
    "    y_pred_train = y_scaler.inverse_transform(y_pred_train.numpy())\n",
    "    y_pred_test = y_scaler.inverse_transform(y_pred_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5c0d59-92ae-403f-b2b6-6e998cd997b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics on train\n",
    "calculate_metrics(train[target], y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db7c38-5f49-4968-9608-22c316a0c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics on test\n",
    "calculate_metrics(test[target], y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c46a0-090a-4877-8513-cfad8cff072a",
   "metadata": {},
   "source": [
    "#### Simulation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a7a17-8b67-47bc-8997-b7075507f418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate on test set\n",
    "y_sim_test_ffnn = simulate(model, x_test_df, na=2, torch_model=True)\n",
    "y_sim_test_ffnn = y_scaler.inverse_transform(y_sim_test_ffnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc059c6-20a1-424c-a4e3-b1cbc1c15305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics on test\n",
    "calculate_metrics(test[target], y_sim_test_ffnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e89ee-bdcf-45ee-8f9c-df8322516407",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,6))\n",
    "gs = fig.add_gridspec(2, hspace=0.1)\n",
    "axs = gs.subplots(sharex=True, sharey=False)\n",
    "\n",
    "axs[0].plot(test['t'], test[target], label='True', color='b')\n",
    "axs[0].plot(test['t'], y_sim_test_linear, label='Simulated (Linear)', color='r', linestyle='-')\n",
    "axs[0].plot(test['t'], y_sim_test_ffnn, label='Simulated (FFNN)', color='g', linestyle='-')\n",
    "axs[0].set_ylabel(r'$y(t)$')\n",
    "axs[0].margins(0.0)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(test['t'], test[target].values.reshape(-1,1) - y_sim_test_linear, label='Simulation error (Linear)', color='r')\n",
    "axs[1].plot(test['t'], test[target].values.reshape(-1,1) - y_sim_test_ffnn, label='Simulation error (FFNN)', color='g')\n",
    "axs[1].set_ylabel(r'$y(t) - \\hat{y}_{sim}(t)$')\n",
    "axs[1].set_xlabel('t')\n",
    "axs[1].margins(0.0)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43af270-b87b-466e-b4e5-85b7ead1e15a",
   "metadata": {},
   "source": [
    "## Modeling: Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e094e4-451a-48ee-be97-e0cba70da869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SystemIdentificationDataset(Dataset):\n",
    "    def __init__(self, input_data, output_data, sequence_length):\n",
    "        self.input_data = input_data\n",
    "        self.output_data = output_data\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data) - self.sequence_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.input_data[idx:idx+self.sequence_length],\n",
    "                self.output_data[idx:idx+self.sequence_length])\n",
    "\n",
    "class SystemIdentificationDataset(Dataset):\n",
    "    def __init__(self, input_data, output_data, sequence_length):\n",
    "        self.input_data = input_data\n",
    "        self.output_data = output_data\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        # Calculate how many non-overlapping sequences fit into the dataset\n",
    "        return (len(self.input_data) // self.sequence_length)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calculate the start index of the sequence\n",
    "        start_idx = idx * self.sequence_length\n",
    "        # Return the non-overlapping sequence\n",
    "        return (self.input_data[start_idx:start_idx + self.sequence_length],\n",
    "                self.output_data[start_idx:start_idx + self.sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41ebb4-308b-48f7-85d6-d62914f04d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "u_scaler = StandardScaler()\n",
    "u_train = u_scaler.fit_transform(train['u(t)'].values.reshape(-1,1))\n",
    "u_test = u_scaler.transform(test['u(t)'].values.reshape(-1,1))\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(train[target].values.reshape(-1,1))\n",
    "y_test = y_scaler.transform(test[target].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abdc651-d79c-4b2d-b66c-003b0f0bf1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to PyTorch tensors\n",
    "u_train = torch.from_numpy(u_train).type(torch.Tensor)\n",
    "u_test = torch.from_numpy(u_test).type(torch.Tensor)\n",
    "\n",
    "y_train = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb6e931-3353-41f9-8e9e-f7fa50a0dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 159\n",
    "sequence_length = 100\n",
    "\n",
    "# Datasets\n",
    "train_dataset = SystemIdentificationDataset(u_train, y_train, sequence_length=sequence_length)\n",
    "test_dataset = SystemIdentificationDataset(u_test, y_test, sequence_length=sequence_length)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb5b7d-5191-47db-9427-4ce0ecd04829",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a7185-ca7a-4460-95e7-cbed8aded297",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u_train_batch, y_train_batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c1acd-629b-4816-9b51-c78548273bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc677a9-3001-48d2-8407-48bfe7929e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Stack multiple RNN layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        \n",
    "        # Forward propagate the RNN\n",
    "        h, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # Return all the output sequence\n",
    "        y = self.fc(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1f6e42-4529-4f9f-99b9-2c4a16ed4730",
   "metadata": {},
   "source": [
    "#### RNN\n",
    "- **Purpose**: A sequential model designed to handle input-output sequence data, featuring multiple stacked RNN layers.\n",
    "- **Initialization** (`__init__`):\n",
    "  - **`input_size`**: Specifies the number of features in the input data. Each feature is processed at each time step.\n",
    "  - **`hidden_size`**: The number of features in the hidden state of each RNN layer.\n",
    "  - **`output_size`**: Number of neurons in the output layer, determining the dimensionality of the output.\n",
    "  - **`num_layers`**: Indicates how many stacked RNN layers are used in the model.\n",
    "  - **Layers**:\n",
    "    - **`self.rnn`**: An RNN layer that stacks `num_layers` of RNN cells. The parameter `batch_first=True` indicates that the input tensors are expected to have a batch dimension first.\n",
    "    - **`self.fc`**: A fully connected (linear) layer that maps the output of the RNN layers to the final output size.\n",
    "- **Forward Pass** (`forward`):\n",
    "  - **Hidden State Initialization**: Starts with initializing the hidden state `h0` to zeros. This tensor has dimensions (`num_layers`, `batch_size`, `hidden_size`).\n",
    "  - **Forward Propagation in RNN**: The input `x` along with the initial hidden state `h0` are passed through the RNN layers. The RNN outputs a new hidden state `h` and a temporary hidden state.\n",
    "  - **Output Generation**: The hidden states `h` from the last RNN layer are then passed through the fully connected layer `self.fc`, which projects them to the desired `output_size`. The result is `y`, representing the output sequence where each time step's hidden state is transformed to an output vector.\n",
    "  - **Return Values**: The function returns `y`, which is the sequence of outputs corresponding to each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5fa511-2ce4-4a5a-b3a9-a6ef2ca55fb6",
   "metadata": {},
   "source": [
    "### Training set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50eb064-340a-4650-9a47-50f917990ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "\n",
    "# Instantiate the model\n",
    "model = RNN(input_size=u_train.shape[1],\n",
    "            hidden_size=20,\n",
    "            output_size=y_train.shape[1],\n",
    "            num_layers=2)\n",
    "print(f\"Total number of trainable model parameters: {get_model_num_params(model)}\")\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define loss function\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b1b7a-4895-4d1c-88e6-e226c8abbc7a",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73189ca3-d5f1-40a3-9112-a2113426c031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = 5000\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    loss = 0.0\n",
    "    for u_train_batch, y_train_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred_train_batch = model(u_train_batch)\n",
    "        loss_batch = loss_function(y_pred_train_batch, y_train_batch)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        loss += loss_batch.item() * x_train_batch.size(0)\n",
    "\n",
    "    # Average loss\n",
    "    loss /= train.shape[0]\n",
    "\n",
    "    # Logging\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch:03d}/{epochs:03d}\"\n",
    "              f\" | Train Loss: {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e0bd1-5a4b-4991-ae0f-494425c57f60",
   "metadata": {},
   "source": [
    "### Predicting and computing evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db5dee-d0b1-4df0-8283-da131968b419",
   "metadata": {},
   "source": [
    "#### Simulation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43728e4a-848a-4bde-8340-7264b8c5c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_sim_test_rnn = model(u_test.unsqueeze(0))\n",
    "\n",
    "y_sim_test_rnn = y_scaler.inverse_transform(y_sim_test_rnn.numpy().squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d54f8-f438-4f68-a04d-aa53cfb98bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(test[target], y_sim_test_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e08ac-fbe5-492a-a37b-3f9453ff2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,6))\n",
    "gs = fig.add_gridspec(2, hspace=0.1)\n",
    "axs = gs.subplots(sharex=True, sharey=False)\n",
    "\n",
    "axs[0].plot(test['t'], test[target], label='True', color='b')\n",
    "axs[0].plot(test['t'], y_sim_test_linear, label='Simulated (Linear)', color='r', linestyle='-')\n",
    "axs[0].plot(test['t'], y_sim_test_ffnn, label='Simulated (FFNN)', color='g', linestyle='-')\n",
    "axs[0].plot(test['t'], y_sim_test_rnn, label='Simulated (RNN)', color='m', linestyle='-')\n",
    "axs[0].set_ylabel(r'$y(t)$')\n",
    "axs[0].margins(0.0)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(test['t'], test[target].values.reshape(-1,1) - y_sim_test_linear, label='Simulation error (Linear)', color='r')\n",
    "axs[1].plot(test['t'], test[target].values.reshape(-1,1) - y_sim_test_ffnn, label='Simulation error (FFNN)', color='g')\n",
    "axs[1].plot(test['t'], test[target].values.reshape(-1,1) - y_sim_test_rnn, label='Simulation error (RNN)', color='m')\n",
    "axs[1].set_ylabel(r'$y(t) - \\hat{y}_{sim}(t)$')\n",
    "axs[1].set_xlabel('t')\n",
    "axs[1].margins(0.0)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.xlim(9000,9250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9fdc4b-3fe1-4119-aa7d-f3bf55f9f59f",
   "metadata": {},
   "source": [
    "## Modeling: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0d12e-066a-4cc9-8e2b-bef1ed9da0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        # (num_layers, batch_size, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # h_n, c_n: tensors of shape (num_layers, batch_size, hidden_size)\n",
    "        out, (h_n, c_n) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        y = self.fc(out)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b11434-d463-45a6-a29c-25aaa8fe1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "\n",
    "# Instantiate the model\n",
    "model = LSTM(input_size=u_train.shape[1],\n",
    "            hidden_size=20,\n",
    "            output_size=y_train.shape[1],\n",
    "            num_layers=2)\n",
    "print(f\"Total number of trainable model parameters: {get_model_num_params(model)}\")\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define loss function\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636e160-f6f0-464d-9630-d8d1a1ccd8e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = 5000\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    loss = 0.0\n",
    "    for u_train_batch, y_train_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred_train_batch = model(u_train_batch)\n",
    "        loss_batch = loss_function(y_pred_train_batch, y_train_batch)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        loss += loss_batch.item() * x_train_batch.size(0)\n",
    "\n",
    "    # Average loss\n",
    "    loss /= train.shape[0]\n",
    "\n",
    "    # Logging\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch:03d}/{epochs:03d}\"\n",
    "              f\" | Train Loss: {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1a2df-397c-493d-a439-e6092c1dde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_sim_test_lstm  = model(u_test.unsqueeze(0))\n",
    "\n",
    "y_sim_test_lstm = y_scaler.inverse_transform(y_sim_test_lstm.numpy().squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbf2a0-c708-4292-8cd6-5b8adb7238d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(test[target], y_sim_test_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466c6c3-427d-4e6d-b218-3101ba9c97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,6))\n",
    "gs = fig.add_gridspec(2, hspace=0.1)\n",
    "axs = gs.subplots(sharex=True, sharey=False)\n",
    "\n",
    "axs[0].plot(test['t'], test[target], label='True', color='b')\n",
    "axs[0].plot(test['t'], y_sim_test_linear, label='Simulated (Linear)', color='r', linestyle='-')\n",
    "axs[0].plot(test['t'], y_sim_test_ffnn, label='Simulated (FFNN)', color='g', linestyle='-')\n",
    "axs[0].plot(test['t'], y_sim_test_rnn, label='Simulated (RNN)', color='m', linestyle='-')\n",
    "axs[0].plot(test['t'], y_sim_test_lstm, label='Simulated (LSTM)', color='k', linestyle='-')\n",
    "axs[0].set_ylabel(r'$y(t)$')\n",
    "axs[0].margins(0.0)\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(test['t'], test[target].values.reshape(-1,1) - y_sim_test_linear, label='Simulation error (Linear)', color='r')\n",
    "axs[1].plot(test['t'], test[target].values.reshape(-1,1) - y_sim_test_ffnn, label='Simulation error (FFNN)', color='g')\n",
    "axs[1].plot(test['t'], test[target].values.reshape(-1,1) - y_sim_test_rnn, label='Simulation error (RNN)', color='m')\n",
    "axs[1].plot(test['t'], test[target].values.reshape(-1,1) - y_sim_test_lstm, label='Simulation error (LSTM)', color='k')\n",
    "axs[1].set_ylabel(r'$y(t) - \\hat{y}_{sim}(t)$')\n",
    "axs[1].set_xlabel('t')\n",
    "axs[1].margins(0.0)\n",
    "axs[1].legend()\n",
    "\n",
    "plt.xlim(9000,9250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fba704-daf8-4807-ac67-0bcee994bcee",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74c43a-eb62-42ef-8ef9-195608bd690b",
   "metadata": {},
   "source": [
    "Familiarize with the code, experiment with different:\n",
    "- number of hidden layers\n",
    "- number of neurons\n",
    "- optimizers\n",
    "- learning rates\n",
    "- epochs number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec5cdc2-d887-41c4-989f-b3c2c80046db",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a591c0-0932-44af-bcca-fe1378965bc0",
   "metadata": {},
   "source": [
    "- [1] https://www.halvorsen.blog/documents/programming/python/resources/powerpoints/Mass-Spring-Damper%20System%20with%20Python.pdf\n",
    "\n",
    "- [2] https://manojsrinivasan.org/Courses/ME8230NonlinearDynamics_Sp2016/LectureNotes/L14_ForcedNonlinearSystemsPhenomena.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
